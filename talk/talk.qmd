---
title: "Reproducibility in cognitive neuroscience: What is the problem?" 
author: Russ Poldrack
institute: Stanford University
title-slide-attributes:
    data-background-image: ./images/stanford_background.jpg
    data-background-opacity: "0.5"
format:
  revealjs: 
    footer: "https://poldrack.github.io/talks-Neurohackademy/"
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    theme: [default, rp-theme.scss]
    height: 1080
    width: 1920
    code-fold: false

---

##  {.centered-bigger}

A search for “fMRI” for FY2024 NIH grants finds:

1816 matching grants

$941M total costs

##

![](./images/nih_wordcloud.png){.absolute top="0%" left="15%" height="80%"}

## {.centered-bigger}

What is the brain dysfunction in major depression?

Meta-analysis of 99 published studies

![](./images/muller_2017_figure2.png){.absolute top="20%" left="10%" height="75%"}

::: {.absolute top=95% left=0% style="font-size: 0.8em; text-align: left;"}
Muller et al, 2017, *JAMA Psychiatry*
:::

##

![](./images/muller_title.png){.absolute top="10%" left="00%" height="40%"}

![](./images/muller_abstract.png){.absolute top="50%" left="00%" height="40%"}

##

![](./images/nih_headline_suicide.png){.absolute top="10%" left="00%" height="80%"}

##

![](./images/nih_headline_suicide.png){.absolute top="10%" left="00%" height="80%"}

![](./images/suicide_pattern.png){.absolute top="30%" left="50%" height="60%"}

##

![](./images/cmu_press_release.png){.absolute top="00%" left="20%" height="90%"}

##

![](./images/just_retraction.png){.absolute top="00%" left="0%" width="100%"}

##

![](./images/ha_culkin.jpg){.absolute top="00%" left="30%" height="60%"}

::: {.absolute top=70% left=22% style="font-size: 1.5em; text-align: center;"}
We seem to have created quite a mess.

How can we fix it?

::: 

## {data-background-image="images/sunlight_disinfectant.jpg" data-background-opacity=".35"}

::: {.absolute top=40% left=8% style="font-size: 2em; text-align: center;"}
"Sunlight is said to be the best disinfectant"

(Louis Brandeis)
::: 

## Towards an ecosystem for open and reproducible neuroscience

![](images/openneuro_landing.png){.absolute top="20%" left="3%" width="45%"}

![](images/nipreps.jpg){.absolute top="20%" left="50%" width="50%"}


## Designing a more reproducible scientific enterprise

![](images/papercutter.png){.absolute top="20%" left="0%" width="45%"}

## Designing a more reproducible scientific enterprise

![](images/papercutter.png){.absolute top="20%" left="0%" width="45%"}

![](images/norman_cover.png){.absolute top="20%" left="60%" width="30%"}


##

![](images/fooling_ourselves.png){.absolute top="00%" left="20%" height="80%"}


::: {.absolute top=85% left=23% style="font-size: 1.2em; text-align: center;"}
82 | NATURE | VOL 526 | 8 OCTOBER 2015
:::

## Improving the choice architecture of science



:::: {.columns}
::: {.column width="50%"}
* Choice architecture
  * particular set of features that drive people toward or away from particular choices
* Nudges
  * Improving incentives
  * Using the power of defaults
  * Providing feedback
  * Expecting and prevent errors
:::
::::


![](images/nudge.png){.absolute top="10%" left="60%" height="70%"}

##

![](images/ioannidis_title.png){.absolute top="00%" left="0%" width="100%"}
![](images/ioannidis_date.png){.absolute top="40%" left="0%" width="100%"}

::: {.absolute top=55% left=0% style="font-size: 1.2em; text-align: left;"}
- The smaller the studies conducted in a scientific field, the less likely the research findings are to be true. 
:::

## Neuroscience research is badly underpowered

![](images/button_title.png){.absolute top="20%" left="0%" width="40%"}
![](images/button_journal.png){.absolute top="45%" left="5%" width="30%"}
![](images/button_figure.png){.absolute top="55%" left="0%" width="45%"}


![](images/dumas_title.png){.absolute top="10%" left="55%" height="35%"}
![](images/dumas_figure.png){.absolute top="50%" left="50%" height="50%"}


## Low power -> unreliable science

:::: {.columns}
::: {.column width="50%"}
Positive Predictive Value (PPV): The probability that a positive result is true
:::
::: {.column width="50%"}
Winner’s Curse: overestimation of effect sizes for significant results
:::
::::
![](images/ppv_formula.png){.absolute top="20%" left="00%" width="50%"}

![](images/ppv_by_power.png){.absolute top="35%" left="00%" width="40%"}

![](images/winners_curse.png){.absolute top="30%" left="50%" width="40%"}

::: {.absolute top=90% left=38% style="text-align: center;"}
Button et al, 2013
:::

## Small samples = high instability of statistical estimates

![](images/schonbrodt.png){.absolute top="15%" left="18%" height="70%"}

::: {.absolute top=90% left=38% style="text-align: center;"}
Schonbrodt & Perugini, 2013
:::


## 

![](images/marek.png){.absolute top="0%" left="17%" height="85%"}

::: {.absolute top=90% left=38% style="text-align: center;"}
Marek et al., 2022
:::

## Small samples + publication bias: the case of candidate genes

![](images/molendijk_title.png){.absolute top="10%" left="0%" height="20%"}

![](images/molendijk_figure.png){.absolute top="30%" left="30%" height="60%"}

## Candidate gene associations fail in well-powered GWAS

![](images/stein_plot.png){.absolute top="20%" left="60%" width="35%"}

![](images/stein_title.png){.absolute top="10%" left="0%" width="80%"}

::: {.absolute top=25% left=1% style="text-align: left;"}
Jason stein et al. for the ENIGMA Consortium
:::

![](images/stein_journal.png){.absolute top="32%" left="1%" width="40%"}

::: {.absolute top=40% left=1% width=50% style="font-size: 1.25em; text-align: left;"}
"In general, previously identified poly­morphisms associated with hippocampal volume showed little association in our meta­-analysis (BDNF, TOMM40, CLU, PICALM, ZNF804A, COMT, DISC1, NRG1, DTNBP1), nor did SNPs previously associated with schizophrenia or bipolar disorder"
:::

## How well powered are fMRI studies?

![](images/Figure1_2023.png){.absolute top="10%" left="5%" width="80%"}


::: {.absolute top=75% left=0% style="text-align: left;"}
- Median study in 2024 (n=36/group) was powered to find a single 200 voxel activation with d~0.67
- Is that plausible?
:::


::: {.absolute top=90% left=0% style="text-align: center;"}
Updated from Poldrack et al., 2017
:::

## Estimating realistic effect sizes

![](images/effect_size_pt1.png){.absolute top="15%" left="0%" height="80%"}

## Estimating realistic effect sizes

![](images/effect_size_pt1.png){.absolute top="15%" left="0%" height="80%"}

![](images/effect_size_pt2.png){.absolute top="15%" left="45%" height="25%"}

## Estimating realistic effect sizes

![](images/effect_size_pt1.png){.absolute top="15%" left="0%" height="80%"}

![](images/effect_size_pt2.png){.absolute top="15%" left="45%" height="25%"}

![](images/effect_size_pt3.png){.absolute top="55%" left="45%" height="35%"}

## Estimating realistic effect sizes

![](images/effect_size_arrows.png){.absolute top="38%" left="45%" height="20%"}


![](images/effect_size_pt1.png){.absolute top="15%" left="0%" height="80%"}

![](images/effect_size_pt2.png){.absolute top="15%" left="45%" height="25%"}

![](images/effect_size_pt3.png){.absolute top="55%" left="45%" height="35%"}

::: {.absolute top="40%" left="75%" width="15%" style="font-size: 1.3em; text-align: center;"}
Unbiased effect size estimate
:::

## What are realistic effect sizes for fMRI?

![](images/effect_size_plot.png){.absolute top="10%" left="5%" height="75%"}

::: {.absolute top=90% left=0% style="text-align: center;"}
Poldrack et al., 2017, *Nature Reviews Neuroscience*
:::

## Depression studies from Muller et al.

![](images/muller_n_by_year_sufficientN.png){.absolute top="10%" left="0%" width="50%"}

::: {.absolute top=17% left=50% style="text-align: left;"}
**Authors must collect at last 20 observations per cell or else provide a compelling cost-of-data-collection justification.** This requirement offers extra protection for the first requirement. Samples smaller than 20 per cell are simply not powerful enough to detect most effects, and so there is usually no good reason to decide in advance to collect such a small number of observations. Smaller samples, it follows, are much more likely to reflect interim data analysis and a flexible termination rule (Simmons et al., 2011)
:::

## Small samples -> variable estimates of predictive accuracy

![](images/varoquaux_variability.png){.absolute top="10%" left="12%" height="75%"}

::: {.absolute top=90% left=0% style="text-align: left;"}
Varoquaux, 2018
:::

## Small samples + publication bias -> inflated accuracy estimates

![](images/varoquaux_decline.png){.absolute top="10%" left="12%" height="75%"}

::: {.absolute top=90% left=0% style="text-align: left;"}
Varoquaux, 2018
:::

## Doing well-powered science as a trainee

![](images/costs_title.png){.absolute top="10%" left="0%" height="35%"}

::: {.absolute top=47% left=0% style="text-align: left;"}

- Underpowered science is futile, but many ECRs don’t have resources to do sufficiently powered studies
- “if you can’t answer the question you love, love the question you can” (Kanwisher, 2017)
- Pivots:
  - Collaborate
  - Use shared data
  - Focus on theory/computational modeling

:::

## A golden age of data sharing

![](images/data_sharing.png){.absolute top="10%" left="0%" width="100%"}

##

![](images/ioannidis_title.png){.absolute top="00%" left="0%" width="100%"}
![](images/ioannidis_date.png){.absolute top="40%" left="0%" width="100%"}

::: {.absolute top=55% left=0% style="font-size: 1.2em; text-align: left;"}
- The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true. 
:::

## 

![](images/processing_options.png){.absolute top="0%" left="15%" height="87%"}

::: {.absolute top=90% left=35% style="text-align: left;"}
Poldrack et al., 2017
:::

##

![](images/carp_secret_title.png){.absolute top="0%" left="0%" height="15%"}
![](images/carp_secret_journal.png){.absolute top="15%" left="0%" height="5%"}
![](images/carp_secret_plots.png){.absolute top="20%" left="5%" width="85%"}

::: {.absolute top=80% left=0% width="100%" style="text-align: center;"}
"data collection and analysis methods were highly flexible across studies, with nearly as many unique analysis pipelines as there were studies in the sample [241]."
:::

## 

![](images/carp_variability_title.png){.absolute top="0%" left="0%" height="25%"}
![](images/carp_variability_result.png){.absolute top="30%" left="5%" width="85%"}

## Machine learning can make it worse


![](images/skocik_title.png){.absolute top="10%" left="0%" height="25%"}
![](images/skocik_plots.png){.absolute top="40%" left="50%" width="50%"}

::: {.absolute top=40% left=0% width="50%" style="text-align: left;"}
"In this article, we use Support Vector Machine (SVM) classifiers, and genetic algorithms to demonstrate the ease by which overfitting can occur, despite the use of cross validation. We demonstrate that comparable and non-generalizable results can be obtained on informative and non-informative (i.e. random) data by iteratively modifying hyperparameters in seemingly innocuous ways."
:::

## It's not just fMRI
![](images/luck_title.png){.absolute top="10%" left="0%" height="35%"}
![](images/luck_names.png){.absolute top="45%" left="0%" height="5%"}


::: {.absolute top=50% left=0% width="100%" style="text-align: left;"}
The purpose of this paper is to demonstrate how common and seemingly innocuous methods for quantifying and analyzing ERP effects can lead to very high rates of significant but bogus effects, with the likelihood of obtaining at least one such bogus effect exceeding 50% in many experiments. 
:::

## Improving reproducibility through pre-registration

:::: {.columns}
::: {.column width="50%"}
- Register analysis plan prior to accessing data
    - Preferably with code based on analysis of simulated data
- This does not prevent exploratory analysis
    - But planned and exploratory analyses should be clearly delineated in the paper
- If the preregistration commits you to something that you learn is bad, you can always deviate
  - as long as you are explicit in the paper
:::
::::

![](images/mriqc_prereg.png){.absolute top="15%" left="55%" width="45%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
http://www.russpoldrack.org/2016/09/why-preregistration-no-longer-makes-me.html
:::

##

:::: {.columns}
::: {.column width="40%"}
- The requirement for clinical trial registration was associated with many more null effects
- This is a “cost” under the current incentives to publish

:::
::::

![](images/kaplan_irvin.png){.absolute top="0%" left="40%" height="85%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
Kaplan & Irvin, 2015
:::

## Pre-registering neuroimaging studies is hard!
:::: {.columns}
::: {.column width="60%"}
- Specify as much as possible
  - How will sample size be determined?
  - Inclusion/exclusion criteria
  - Primary hypotheses to be tested
  - Anatomical regions of interest
  - Analysis plan
    - Preferably with code tested on existing or simulated data
:::
::: {.column width="40%"}
![](images/fmri-prereg.png){.absolute top="15%" left=40%" height="85%"}


:::
::::

::: {.absolute top=70% left="55%" style="text-align: center;"}
https://prereg-psych.org/create/
:::

##

::: {.absolute top=30% width="100%" style="font-size: 1.5em; text-align: center;"}

Pre-registration prevents p-hacking but does not eliminate analytic variability
\
\
How variable are neuroimaging analysis workflows in the wild?
\
\
What is the effect on scientific inferences?
:::

##

![](images/narps_group.png){.absolute top="0%" left="10%" height="90%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## Data collection: Mixed gambles task

- Functional MRI data for 108 subjects collected at Tel Aviv University

![](images/narps_task.png){.absolute top="20%" left="10%" height="70%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## Study recruitment

- Analysis teams recruited via social media and conferences
  - Up to 3 people each
  - Signed non-disclosure agreement
  - Offered co-authorship on initial paper
- Raw dataset (~400GB) distributed to 82 teams via Globus
- Teams given ~3 months to provide Y/N answers to 9 hypothesis tests:
  - Is there significant activation in <brain area> for <feature of experimental design>?
- Using their standard analysis workflow
  - Only restriction was that analysis should include whole brain

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## Results collection

- Received final results from 70 teams
- Teams reported their yes/no decisions for each hypothesis
  - Also uploaded the whole-brain statistical maps before and after thresholding

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## How variable are workflows in the wild?

![](images/cobidas_title.png){.absolute top="20%" left="10%" width="70%"}

::: {.absolute top=55% width="100%" style="text-align: center;"}
- Teams provided a detailed written description of analysis workflows
- No 2 teams used an identical workflow
- Even with detailed written description it was often impossible to tell exactly what was done!
:::

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## What is the effect of analytic variability on outcomes?

![](images/narps_outcomes.png){.absolute top="10%" left="20%" height="60%"}

::: {.absolute top=75%}
- Across teams there were 33 different patterns of outcomes
- For any hypothesis, there are at least 4 workflows that can give a positive result
:::

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## Variability of whole-brain results

::: {.absolute top=15% width="100%" style="font-size: 1.4em; text-align: center;"}
Proportion of teams with activity in each voxel
:::

![](images/narps_wholebrain.png){.absolute top="30%" left="15%" width="70%"}

::: {.absolute top=70% width="100%" style="font-size: 1.4em; text-align: center;"}
Maximum overlap for all hypotheses: 76%
:::

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

<!--
##

![](images/narps_table.png){.absolute top="20%" left="0%" width="100%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::
-->

##

![](images/narps_corrmap1){.absolute top="0%" left="0%" height="90%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

##

![](images/narps_corrmap2){.absolute top="0%" left="0%" height="90%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## Meta-analysis across groups shows reliable findings

![](images/narps_meta.png){.absolute top="10%" left="8%" height="80%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
Botvinik-Nezer et al., 2020, *Nature*
:::

## How to improve analytic reproducibility

![](images/elife_multi_analyst.png){.absolute top="10%" left="0%" height="30%"}
![](images/blind_analysis.png){.absolute top="50%" left="0%" height="45%"}
![](images/simulated_data_gelman.png){.absolute top="30%" left="50%" width="45%"}


## Multiverse analysis


:::: {.columns}
::: {.column width="30%"}
* If the same dataset is analyzed in different ways, do we get the same answer?
  * Previous work shows large effects of different analysis workflows
  * “Vibration of effects” (Ioannidis)

:::
::::


![](images/steegen.png){.absolute top="10%" left="40%" height="60%"}

::: {.absolute top=80% left="60%" style="text-align: center;"}
Steegen et al., 2016
:::

## A multiverse example: Are there analytic choices that consistently improve test-retest reliability?

:::: {.columns}
::: {.column width="30%"}
* Test-retest reliability is essential for individual difference analyses
* Previous work has shown low but variable reliability
* How does this relate to analytic choices?
:::
::::


![](images/elliott.png){.absolute top="20%" left="35%" height="50%"}

::: {.absolute top=80% left="60%" style="text-align: center;"}
Elliott et al., 2020
:::

## Multiverse analysis of MID reliability

![](images/mid_reliability.png){.absolute top="10%" left="1%" height="70%"}

::: {.absolute top=80% left="60%" style="text-align: center;"}
Demidenko et al., 2024
:::


##

:::: {.columns}
::: {.column width="30%"}
* Tested effects of several analytic choices over 240 pipelines
  * Smoothing
  * Motion modeling
  * Model specification
  * Contrast specification
* Overall, reliability was low
  * But it varied substantially across models and contrasts
:::
::::


![](images/demidenko_multiverse.png){.absolute top="5%" left="40%" height="80%"}

::: {.absolute top=80% left="20%" style="text-align: center;"}
Demidenko et al., 2024
:::

## 

::: {.absolute top=30% width="100%" style="font-size: 1.5em; text-align: center;"}
How many of you have written computer code in the course of your research?
:::

##

::: {.absolute top=30% width="100%" style="font-size: 1.5em; text-align: center;"}
How many of you have been trained in software engineering?
:::


##

::: {.absolute top=30% width="100%" style="font-size: 1.5em; text-align: center;"}
How many of you have ever written a test for your code?
:::

## Software errors are a threat to reproducibility

![](images/chang_abstracts.png){.absolute top="20%" left="15%" height="80%"}

##

![](images/chang_retraction.png){.absolute top="0%" left="10%" height="100%"}

## Small errors can have big effects

::: {.absolute top=10% height="70%" left="0%" style="font-size: 1.5em;"}
```
# 23-class classification problem

skf=StratifiedKFold(labels,8)

if trainsvm:
    pred=N.zeros(len(labels))
    for train,test in skf:
        clf=LinearSVC()
        clf.fit(data[train],labels[train])
        pred[test]=clf.predict(data[test])
```
:::

::: {.absolute top=65% height="70%" left="0%" style="font-size: 1.5em;"}
**Results: 93% accuracy**
:::

::: {.absolute top=90% width="100%" style="text-align: center;"}
http://www.russpoldrack.org/2013/02/anatomy-of-coding-error.html
:::

## Small errors can have big effects

::: {.absolute top=10% height="70%" left="0%" style="font-size: 1.5em;"}
```
# 23-class classification problem

skf=StratifiedKFold(labels,8)

if trainsvm:
    pred=N.zeros(len(labels))
    for train,test in skf:
        clf=LinearSVC()
        clf.fit(data[train],labels[train])
        pred[test]=clf.predict(data[test])
```
:::

::: {.absolute top=65% height="70%" left="0%" style="font-size: 1.5em;"}
**Results: 93% accuracy**
:::

::: {.absolute top=90% width="100%" style="text-align: center;"}
http://www.russpoldrack.org/2013/02/anatomy-of-coding-error.html
:::

::: {.absolute top=47% left="65%" style="font-size: 1.5em;"}
```
data[:,train]
data[:,test]
```
:::

::: {.absolute top=65% height="70%" left="65%" style="font-size: 1.5em;"}
**Results: 53% accuracy**
:::

## Software errors hit home

![](images/error1.png){.absolute top="10%" left="0%" width="65%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
http://reproducibility.stanford.edu/coding-error-postmortem/
:::

## Software errors hit home

![](images/error2.png){.absolute top="10%" left="0%" width="67%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
http://reproducibility.stanford.edu/coding-error-postmortem/
:::

## Software errors hit home

![](images/error3.png){.absolute top="10%" left="0%" width="67%"}

::: {.absolute top=90% width="100%" style="text-align: center;"}
http://reproducibility.stanford.edu/coding-error-postmortem/
:::

## Bug-hacking

![](images/bug_hacking.png){.absolute top="10%" left="0%" width="100%"}

::: {.absolute top=85% width="100%" style="font-size: 1.25em; text-align: center;"}
- Bugs that confirm our predictions are less likely to be uncovered than bugs that disconfirm them
:::

## The principle of assumed error

- Whenever you find a seemingly good result (e.g. one that fits your predictions), assume that it occurred due to an error in your code
- Protects from “bug hacking”


::: {.absolute top=90% width="100%" style="text-align: center;"}
http://www.russpoldrack.org/2016/08/the-principle-of-assumed-error.html
:::

## Coding for reproducibility

:::: {.columns}
::: {.column width="50%"}
- High quality code should be:
  - Readable
  - Robust
  - Modular
  - Well-tested
- Coding is a craft
  - The only way to improve one’s skills is through consistent and deliberate practice
:::
::::

![](images/software_carpentry.png){.absolute top="20%" left="60%" width="30%"}

::: {.absolute top="55%" left="55%" style="font-size: 1.3em; text-align: center;"}
https://software-carpentry.org
:::


## Coding style

- “code is read much more often than it is written” so readability counts (G. van Rossum) 
- Nearly all languages have conventions for coding style
  - Following them makes your code easier for others to understand
  - “others” includes your future self!
- There are also language-independent principles of software design

![](images/coding_books.png){.absolute top="50%" left="0%" width="100%"}

## Commenting is not a magic balm for bad code

- Comments should help the reader to know as much as the writer knows about the code
  - Should express intention when it’s not obvious
- “Clear and expressive code with few comments is far superior to cluttered and complex code with lots of comments” (Robert Martin, Clean Code)
- “Don’t comment bad code — rewrite it” (Kernighan & Plaugher)

## Code quality analysis and repair

- Static analysis (pylint, flake8, etc)
  - Checks for errors and adherence to Python style guidelines
  - Can be run automatically within editor any time code is saved
- Automated formatting tools can help ensure good code formatting
  - black/blue for Python
- Collaborator: “Fixing the style made your code so much easier to read!”

![](images/pylint.png){.absolute top="40%" left="0%" width="80%"}

## Code review

:::: {.columns}
::: {.column width="50%"}
- Linus’s law
  - "given enough eyeballs, all bugs are shallow.”
- Code review as a group is a great way to learn coding skills
- AI tools have become very good at code review
:::
::::

![](images/petre_title.png){.absolute top="0%" left="55%" width="40%"}
![](images/petre_abstract.png){.absolute top="26%" left="55%" height="60%"}

## Software testing

- Smoke tests
  - Does everything run without exploding?
- Sanity checks
  - Are values within reasonable ranges?
- Unit tests
  - Does the function do what it is supposed to do?

::: {.absolute top="75%" left="0%" width="100%" style="text-align: center;"}
https://github.com/poldrack/pytest_tutorial
:::

##

![](images/plosone_title.png){.absolute top="0%" left="0%" width="50%"}

::: {.absolute top="40%" left="0%" width="100%" style="font-size: 1.2em; text-align: left;"}

The dataset included two notable age outliers (reported ages 5 and 32757).

Specifically, the statement on page 9 “age turned out not to correlate with any of the indicator variables” is incorrect. It should read instead “age correlated significantly with 3 latent indicator variables (Vaccinations: .219, p < .0001; Conservatism: .169, p < .001; Conspiracist ideation: -.140, maximum likelihood p < .0001, bootstrapped p = .004), and straddled significance for a fourth (Free Market: .08, p%.05).”

:::

##

::: {.absolute top=10% height="70%" left="0%" style="font-size: 1.5em;"}
```
In [1]: age=32757

In [2]: assert age>12 and age<120
------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-2-37de876b5fda> in <module>()
----> 1 assert age>12 and age<120

AssertionError:
```
:::

## Test-driven development

:::: {.columns}
::: {.column width="50%"}
- Write test cases based on the intended behavior of the code
- Run tests and continue to modify code until the tests pass
- Add tests for any new requirements
:::
::::

![](images/TDD-1-640x770.png){.absolute top="0%" left="55%" width="40%"}

::: {.absolute top=90%  left="55%" style="font-size: 0.8em;"}
https://www.browserstack.com/guide/tdd-vs-bdd-vs-atdd
:::

## Automated testing

![](images/github_actions.png){.absolute top="10%" left="10%" height="80%"}

## Automated testing

![](images/github_actions_workflow.png){.absolute top="10%" left="10%" height="80%"}

## Automated testing

![](images/github_actions_output.png){.absolute top="10%" left="10%" height="80%"}

## 

![](images/bcbs_cover.png){.absolute top="0%" left="15%" height="60%"}

::: {.absolute top="75%" left="0%" width="100%" style="text-align: center;"}
https://poldrack.github.io/BetterCodeBetterScience

New testing sections daily this week at https://russpoldrack.substack.com/
:::



## Reproducibility vs. validity

:::: {.columns}
::: {.column width="40%"}
- Reproducibility does not ensure validity
  - The code could be reproducibly wrong!
:::
::::


![](images/ReliabilityValidity-1.png){.absolute top="10%" left="40%" height="80%"}


## Code validation

- Parameter recovery
  - generate synthetic data with a known answer, and make sure that your code can recover the known answer
  - Best to do this before ever touching the real data!
- Null/randomization testing
  - Generate data with no effect (either synthetic or via randomization of real data) and make sure that no effect is found
- There are increasingly powerful frameworks for generating simulated data
  - Python: Synthetic Data Vault (https://sdv.dev/SDV/)

## Conclusions

- Cognitive neuroscience has a reproducibility problem
  - Likely not very different from other areas of science with complex computational workflows and large datasets
- Statistical power is one key to solving the problem
- Software engineering tools can help ensure reproducibility and validity of complex analyses
- The tools that you will learn at Neurohackademy will help you do better science! 

##

![](images/poldracklab_acknowledgments.png){.absolute top="0%" left="0%" height="90%"}
